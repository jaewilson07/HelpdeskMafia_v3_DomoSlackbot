{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic-ai\n",
      "  Using cached pydantic_ai-0.0.49-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-ai-slim==0.0.49 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached pydantic_ai_slim-0.0.49-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.2.2)\n",
      "Requirement already satisfied: griffe>=1.3.2 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.7.2)\n",
      "Requirement already satisfied: httpx>=0.27 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.31.1)\n",
      "Requirement already satisfied: pydantic-graph==0.0.49 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.0.49)\n",
      "Requirement already satisfied: pydantic>=2.10 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.11.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.4.0)\n",
      "Collecting anthropic>=0.49.0 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting boto3>=1.34.116 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached boto3-1.37.26-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.6.1)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.0.50)\n",
      "Requirement already satisfied: rich>=13 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (14.0.0)\n",
      "Collecting cohere>=5.13.11 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached cohere-5.14.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pydantic-evals==0.0.49 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.0.49)\n",
      "Collecting groq>=0.15.0 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting mcp>=1.4.1 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached mcp-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: mistralai>=1.2.5 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.6.0)\n",
      "Requirement already satisfied: openai>=1.67.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.70.0)\n",
      "Collecting google-auth>=2.36.0 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: requests>=2.32.3 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.32.3)\n",
      "Requirement already satisfied: anyio>=0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-evals==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (4.9.0)\n",
      "Requirement already satisfied: logfire-api>=1.2.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-evals==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (4.13.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.26 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.37.26)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.11.4)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.33.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.21.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.32.0.20250328)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (4.9)\n",
      "Requirement already satisfied: colorama>=0.4 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from griffe>=1.3.2->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.4.6)\n",
      "Requirement already satisfied: certifi in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.8.1)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: starlette>=0.27 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.46.1)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.34.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from openai>=1.67.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (4.67.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (8.6.1)\n",
      "Requirement already satisfied: wcwidth in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from prompt-toolkit>=3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic>=2.10->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2.19.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.49->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (0.30.1)\n",
      "Requirement already satisfied: click>=7.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from uvicorn>=0.23.1->mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (8.1.8)\n",
      "Requirement already satisfied: filelock in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github\\domo-helpdeskmafia_v3\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.0.49->pydantic-ai) (6.0.2)\n",
      "Using cached pydantic_ai-0.0.49-py3-none-any.whl (10 kB)\n",
      "Using cached pydantic_ai_slim-0.0.49-py3-none-any.whl (142 kB)\n",
      "Using cached anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "Using cached boto3-1.37.26-py3-none-any.whl (139 kB)\n",
      "Using cached cohere-5.14.2-py3-none-any.whl (259 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached groq-0.22.0-py3-none-any.whl (126 kB)\n",
      "Using cached mcp-1.6.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: google-auth, groq, anthropic, pydantic-ai-slim, mcp, cohere, boto3, pydantic-ai\n",
      "Successfully installed anthropic-0.49.0 boto3-1.37.26 cohere-5.14.2 google-auth-2.38.0 groq-0.22.0 mcp-1.6.0 pydantic-ai-0.0.49 pydantic-ai-slim-0.0.49\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OpenAIModel in module pydantic_ai.models.openai:\n",
      "\n",
      "class OpenAIModel(pydantic_ai.models.Model)\n",
      " |  OpenAIModel(model_name: 'OpenAIModelName', *, provider: \"Literal['openai', 'deepseek', 'azure'] | Provider[AsyncOpenAI]\" = 'openai', system_prompt_role: 'OpenAISystemPromptRole | None' = None)\n",
      " |  \n",
      " |  A model that uses the OpenAI API.\n",
      " |  \n",
      " |  Internally, this uses the [OpenAI Python client](https://github.com/openai/openai-python) to interact with the API.\n",
      " |  \n",
      " |  Apart from `__init__`, all methods are private or match those of the base class.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OpenAIModel\n",
      " |      pydantic_ai.models.Model\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, model_name: 'OpenAIModelName', *, provider: \"Literal['openai', 'deepseek', 'azure'] | Provider[AsyncOpenAI]\" = 'openai', system_prompt_role: 'OpenAISystemPromptRole | None' = None)\n",
      " |      Initialize an OpenAI model.\n",
      " |      \n",
      " |      Args:\n",
      " |          model_name: The name of the OpenAI model to use. List of model names available\n",
      " |              [here](https://github.com/openai/openai-python/blob/v1.54.3/src/openai/types/chat_model.py#L7)\n",
      " |              (Unfortunately, despite being ask to do so, OpenAI do not provide `.inv` files for their API).\n",
      " |          provider: The provider to use. Defaults to `'openai'`.\n",
      " |          system_prompt_role: The role to use for the system prompt message. If not provided, defaults to `'system'`.\n",
      " |              In the future, this may be inferred from the model name.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  async request(self, messages: 'list[ModelMessage]', model_settings: 'ModelSettings | None', model_request_parameters: 'ModelRequestParameters') -> 'tuple[ModelResponse, usage.Usage]'\n",
      " |      Make a request to the model.\n",
      " |  \n",
      " |  request_stream(self, messages: 'list[ModelMessage]', model_settings: 'ModelSettings | None', model_request_parameters: 'ModelRequestParameters') -> 'AsyncIterator[StreamedResponse]'\n",
      " |      Make a request to the model and return a streaming response.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  base_url\n",
      " |      The base URL for the provider API, if available.\n",
      " |  \n",
      " |  model_name\n",
      " |      The model name.\n",
      " |  \n",
      " |  system\n",
      " |      The system / model provider.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_model_name': 'OpenAIModelName', '_system': 'str',...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'_model_name': Field(name='_model_name',type='...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=False,repr=True,eq=True,o...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('client', 'system_prompt_role', '_model_name', '_sys...\n",
      " |  \n",
      " |  system_prompt_role = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic_ai.models.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "help(OpenAIModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
